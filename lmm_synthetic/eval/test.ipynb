{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsight import NNsight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPTJForCausalLM, AutoTokenizer  \n",
    "model_path = r\"C:\\Users\\allan\\ResearchStuff\\checkpoint-1953\"\n",
    "\n",
    "gptj = GPTJForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = NNsight(gptj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\allan\\Anaconda3\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello world, this is a test, example sentence\"\n",
    "\n",
    "input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "gen_tokens = gptj.generate(\n",
    "    input_ids,\n",
    "    temperature=0.9,\n",
    "    max_length=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "\n",
    "for i in range(len(input_ids[0])):\n",
    "    tokens.append(tokenizer.decode(input_ids[0][i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Token 0: H\n",
      " Token 1: el\n",
      " Token 2: l\n",
      " Token 3: o\n",
      " Token 4:  \n",
      " Token 5: w\n",
      " Token 6: o\n",
      " Token 7: r\n",
      " Token 8: l\n",
      " Token 9: d\n",
      " Token 10: ,\n",
      " Token 11:  \n",
      " Token 12: t\n",
      " Token 13: hi\n",
      " Token 14: s\n",
      " Token 15:  is\n",
      " Token 16:  a\n",
      " Token 17:  \n",
      " Token 18: t\n",
      " Token 19: e\n",
      " Token 20: s\n",
      " Token 21: t\n",
      " Token 22: ,\n",
      " Token 23:  \n",
      " Token 24: e\n",
      " Token 25: x\n",
      " Token 26: a\n",
      " Token 27: m\n",
      " Token 28: p\n",
      " Token 29: l\n",
      " Token 30: e\n",
      " Token 31:  s\n",
      " Token 32: e\n",
      " Token 33: nt\n",
      " Token 34: e\n",
      " Token 35: n\n",
      " Token 36: c\n",
      " Token 37: e\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(tokens)):\n",
    "    print(f\" Token {i}: {tokens[i]}\")  #end = \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[38, 47, 51, 41]])\n",
      "GPTJ\n",
      "GPTJ\n"
     ]
    }
   ],
   "source": [
    "text = \"GPTJ\"\n",
    "\n",
    "# Get input_ids (tokenized form of the input text)\n",
    "input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "print(input_ids)\n",
    "# Decode the input_ids back to actual text (i.e., the input tokens as text)\n",
    "decoded_input = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(decoded_input)\n",
    "# Print the decoded input (this will show the actual letters/words)\n",
    "print(decoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "with test.trace(gen_tokens) as tracer:\n",
    "    for i in range(12):\n",
    "        outputs.append((f\"Layer {i} output\", test.transformer.h[i].output.save()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Layer 0 output', (tensor([[[ -0.6713,  -1.8850,   0.1562,  ...,  -0.4049,  -1.4577,  -1.6844],\n",
      "         [ -1.0820,  -1.5449,   0.8616,  ...,   2.4094,  -1.6196,   0.0721],\n",
      "         [  0.4574,  -3.6470,   0.2879,  ...,   2.5716,   1.5716,   0.9055],\n",
      "         ...,\n",
      "         [ -0.7576, -21.3116,  -1.5330,  ...,  14.6248,  -8.7274,  -5.4263],\n",
      "         [  5.7702, -19.8443,  -0.8391,  ...,  11.9283,   4.0851,  -6.8185],\n",
      "         [-22.2720, -44.1820,   1.0867,  ...,  45.3139, -15.6399, -14.0367]]],\n",
      "       grad_fn=<AddBackward0>), DynamicCache()))\n",
      "('Layer 1 output', (tensor([[[  1.7886, -14.3946,  -1.2068,  ...,   1.4213,   1.2189,   9.3767],\n",
      "         [ -0.1867,  -9.9831,   0.5291,  ...,   6.7367,  -0.7676,   7.6162],\n",
      "         [ -2.4369,  -6.1992,   0.5612,  ...,   5.5680,  -1.8104,   1.2986],\n",
      "         ...,\n",
      "         [ -1.2394, -26.9737,   2.3762,  ...,  20.9325,  -7.4116,   1.9497],\n",
      "         [  5.2473, -26.4591,   3.8794,  ...,  19.6579,   3.9122,  -1.0884],\n",
      "         [-25.1284, -47.9973,   8.6620,  ...,  59.5282, -15.4591, -11.8366]]],\n",
      "       grad_fn=<AddBackward0>), DynamicCache()))\n",
      "('Layer 2 output', (tensor([[[  2.3868, -11.0924,  -1.3673,  ...,  16.3749,  -2.8307,   5.8288],\n",
      "         [  5.1312,  -4.4111,   0.5994,  ...,  20.9291,  -2.5301,   6.3569],\n",
      "         [  4.9760,  -4.6263,  -0.5591,  ...,  18.9429,  -1.2174,   3.0265],\n",
      "         ...,\n",
      "         [ -2.0434, -23.3745,  -2.6820,  ...,  14.0018, -13.5192,  -4.3918],\n",
      "         [  1.0765, -22.3642,  -1.4385,  ...,   8.0135,  -4.1456,  -9.7100],\n",
      "         [-21.7682, -40.2925,  -4.5138,  ...,  49.4527, -11.9403, -10.7240]]],\n",
      "       grad_fn=<AddBackward0>), DynamicCache()))\n",
      "('Layer 3 output', (tensor([[[ 1.6015e+00, -1.0438e+01, -1.7078e-01,  ...,  1.4705e+01,\n",
      "          -3.2042e+00,  4.1097e+00],\n",
      "         [ 3.6660e+00, -4.5505e+00,  1.5236e+00,  ...,  1.8161e+01,\n",
      "          -2.3102e+00,  4.4283e+00],\n",
      "         [ 4.2042e+00, -4.5903e+00,  8.1172e-01,  ...,  1.7049e+01,\n",
      "          -6.0770e-01,  1.8392e+00],\n",
      "         ...,\n",
      "         [-1.0229e+00, -2.2358e+01, -6.3206e-01,  ...,  1.1565e+01,\n",
      "          -1.3586e+01, -2.1483e+00],\n",
      "         [ 1.3870e+00, -2.2243e+01,  2.0312e-02,  ...,  6.9415e+00,\n",
      "          -4.1087e+00, -8.3868e+00],\n",
      "         [-1.7241e+01, -3.5704e+01, -9.1138e+00,  ...,  4.2523e+01,\n",
      "          -9.8347e+00, -1.1695e+01]]], grad_fn=<AddBackward0>), DynamicCache()))\n",
      "('Layer 4 output', (tensor([[[  1.2595,  -9.0216,   0.2235,  ...,  11.4625,  -3.7360,   3.4432],\n",
      "         [  2.7238,  -4.2939,   2.6081,  ...,  14.3352,  -2.2391,   3.2437],\n",
      "         [  2.7064,  -3.4243,   2.1757,  ...,  12.6687,  -0.3125,   1.6210],\n",
      "         ...,\n",
      "         [ -0.5695, -22.0531,   2.3528,  ...,   8.2502, -12.8967,  -3.1791],\n",
      "         [  1.8667, -21.8196,   3.5550,  ...,   5.3212,  -3.3766,  -9.3198],\n",
      "         [-14.0749, -33.8239,  -7.5789,  ...,  38.2341,  -8.4840, -13.0538]]],\n",
      "       grad_fn=<AddBackward0>), DynamicCache()))\n",
      "('Layer 5 output', (tensor([[[  0.3035,  -6.9694,  -0.8814,  ...,  10.7265,  -3.0516,   2.8525],\n",
      "         [  1.5755,  -2.8720,   1.4942,  ...,  13.5706,  -1.8969,   2.9174],\n",
      "         [  1.4120,  -2.5078,   1.4990,  ...,  11.6811,   0.0667,   1.0732],\n",
      "         ...,\n",
      "         [  0.9057, -19.4815,   3.6010,  ...,   7.5932, -10.9837,  -3.8790],\n",
      "         [  2.8906, -20.6366,   4.2072,  ...,   4.7018,  -2.1506, -10.2870],\n",
      "         [-11.4340, -30.6336,  -8.2560,  ...,  29.9220,  -7.5983, -13.9761]]],\n",
      "       grad_fn=<AddBackward0>), DynamicCache()))\n",
      "('Layer 6 output', (tensor([[[ -0.1882,  -6.6684,  -0.9110,  ...,   7.6622,  -2.1388,   3.2341],\n",
      "         [  1.1064,  -3.1096,   1.0571,  ...,   9.7983,  -1.0536,   3.1338],\n",
      "         [  0.7773,  -2.7555,   1.8394,  ...,   9.0175,   1.1193,   1.1496],\n",
      "         ...,\n",
      "         [  1.5065, -18.6164,   5.5888,  ...,   6.9495,  -9.5186,  -2.1501],\n",
      "         [  3.6172, -18.4956,   5.5829,  ...,   5.6944,  -2.0997,  -9.8447],\n",
      "         [ -8.3201, -26.8625,  -7.2347,  ...,  23.3668,  -5.5944, -12.8600]]],\n",
      "       grad_fn=<AddBackward0>), DynamicCache()))\n",
      "('Layer 7 output', (tensor([[[  0.2153,  -4.8449,  -0.9570,  ...,   4.9180,  -1.6030,   2.8370],\n",
      "         [  1.5460,  -1.8386,   0.7502,  ...,   6.4334,  -1.2196,   2.5771],\n",
      "         [  0.0863,  -1.3220,   1.6564,  ...,   5.0036,   1.0611,   0.1882],\n",
      "         ...,\n",
      "         [  3.5674, -16.8881,   6.2248,  ...,   4.5513,  -8.5666,  -2.5313],\n",
      "         [  4.9984, -18.4673,   6.4765,  ...,   2.3594,  -2.6897, -10.5426],\n",
      "         [ -4.7138, -23.5755,  -6.4362,  ...,  17.3188,  -4.8572, -14.0807]]],\n",
      "       grad_fn=<AddBackward0>), DynamicCache()))\n",
      "('Layer 8 output', (tensor([[[ 1.5436e-01, -2.8558e+00,  8.8998e-03,  ...,  2.8404e+00,\n",
      "          -9.5053e-01,  3.4078e+00],\n",
      "         [ 1.8670e+00, -1.4277e-01,  1.6591e+00,  ...,  4.0323e+00,\n",
      "          -6.3729e-01,  2.7482e+00],\n",
      "         [-1.0374e+00, -7.1265e-02,  2.1110e+00,  ...,  3.2158e+00,\n",
      "           1.0795e+00,  8.6598e-01],\n",
      "         ...,\n",
      "         [ 4.8274e+00, -1.4360e+01,  6.4115e+00,  ...,  4.5798e+00,\n",
      "          -8.4397e+00, -3.5210e+00],\n",
      "         [ 5.8163e+00, -1.6020e+01,  7.1764e+00,  ...,  2.8500e+00,\n",
      "          -1.1300e+00, -1.0047e+01],\n",
      "         [-2.2670e+00, -1.8534e+01, -3.2254e+00,  ...,  1.3707e+01,\n",
      "          -1.9275e+00, -1.2394e+01]]], grad_fn=<AddBackward0>), DynamicCache()))\n",
      "('Layer 9 output', (tensor([[[ -1.1634,  -1.9008,   1.9517,  ...,   1.5229,  -1.3659,   3.2471],\n",
      "         [  0.9180,   0.7006,   3.6610,  ...,   2.4118,  -1.0561,   2.5477],\n",
      "         [ -2.5942,   0.2701,   4.0932,  ...,   2.1435,   0.9404,   0.5358],\n",
      "         ...,\n",
      "         [  3.9272, -13.1335,   6.3555,  ...,   2.4860,  -7.9576,  -3.5515],\n",
      "         [  4.4045, -12.4814,   9.4565,  ...,   2.2430,  -0.0715,  -9.3327],\n",
      "         [ -1.1797, -14.2949,   0.2658,  ...,  11.1552,   1.0089, -10.6487]]],\n",
      "       grad_fn=<AddBackward0>), DynamicCache()))\n",
      "('Layer 10 output', (tensor([[[ -2.4176,  -0.4654,   3.1624,  ...,   1.1281,  -0.7692,   3.4435],\n",
      "         [  0.1196,   1.4508,   4.8782,  ...,   2.1553,  -0.8098,   2.5482],\n",
      "         [ -4.7921,   0.9221,   4.9542,  ...,   1.4626,   1.5180,   0.5484],\n",
      "         ...,\n",
      "         [  3.2976, -12.1774,   7.3408,  ...,   1.4951,  -5.6451,  -1.9726],\n",
      "         [  1.8073,  -7.6520,  13.6434,  ...,   6.4617,  -0.1685,  -9.1441],\n",
      "         [  1.7515, -12.2990,   2.8749,  ...,  10.1640,   1.7208,  -9.0302]]],\n",
      "       grad_fn=<AddBackward0>), DynamicCache()))\n",
      "('Layer 11 output', (tensor([[[ -3.8036,   4.2859,   4.6002,  ...,   0.6859,  -1.3062,   3.4593],\n",
      "         [ -1.2668,   5.6039,   6.5484,  ...,   1.1877,  -1.5126,   2.2219],\n",
      "         [ -7.3138,   3.8452,   6.3068,  ...,   1.5840,   1.5178,   0.6992],\n",
      "         ...,\n",
      "         [  6.3861, -11.1618,   4.0712,  ...,   5.3928,  -4.4089,  -0.1944],\n",
      "         [  1.0646,  -3.7882,  17.3333,  ...,  11.9920,  -0.5879,  -8.1134],\n",
      "         [  3.4615,  -1.4723,  -2.5166,  ...,  12.2055,   6.8301,  -3.5714]]],\n",
      "       grad_fn=<AddBackward0>), DynamicCache()))\n"
     ]
    }
   ],
   "source": [
    "for layer in outputs: \n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\"\"\"output = test.transformer.h[i].output.save()\n",
    "        print(i)\n",
    "        print(output)\n",
    "        print(output.type)\n",
    "        outputs.append((f\"Layer {i} output\", test.transformer.h[i].output.save()))  \"\"\"\n",
    "\n",
    "outputs = []    \n",
    "probs= []\n",
    "with test.trace(gen_tokens) as tracer:\n",
    "    for i in range(12):\n",
    "        outputs.append((f\"Layer {i} output\", test.transformer.h[i].output.save()))\n",
    "        probs.append(test.transformer.h[i].output.save())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "new_prob = []\n",
    "\n",
    "for prob in probs:\n",
    "    new = torch.nn.functional.softmax(prob[0], dim=-1)\n",
    "    new_prob.append(new)\n",
    "\n",
    "max_probs, tokens = probs.max(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\nectect', 'ectZTheect', 'ectTheect', 'ectectect', 'ectect', 'ectectect', 'ect', 'ect', 'ect', 'ect', 'ect dogectiz', '\\n- dog cect']\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for t in tokens:\n",
    "    words.append(tokenizer.decode(t))\n",
    "\n",
    "print(words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
